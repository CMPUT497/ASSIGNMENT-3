\documentclass[11pt]{article}
\usepackage{acl}
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{url}
\usepackage{booktabs}
\usepackage{titlesec}
\usepackage[english, bidi=basic]{babel}
\babelfont[urdu]{rm}{Amiri} % Urdu font setup


\setlength{\parskip}{0pt}

\author{
  \begin{tabular}{c c}
    \textbf{Chirooth Girigowda} & \textbf{Sahir Momin} \\
    \text{girigowd@ualberta.ca} & \text{smomin1@ualberta.ca} \\
    \text{University of Alberta} & \text{University of Alberta}
  \end{tabular}
}


\title{Assignment 3: Concepts \\ ExpandNet Implementation of English-to-Urdu Sense Projection}

\begin{document}
\maketitle

\section{Introduction}
In this assignment we implemented sense projection on Urdu words, from English sentences using ExpandNet. We performed translation with a translator \textbf{NLLB}. We then used \textbf{dbalign} along with a Bilingual dictionary(en-ur) that we found via wikiextractor and other dictionary resources(cite all of them), with this combined dictionary and translations we get the alignment from english to urdu words on all the sentences. Finally, we project the senses of the english tokens onto the urdu lemmas based on the alignment. These 3 steps which are part of ExpandNet was used to extend the idea of ExpandNet for en-ur language pair, proving that this method can be extended to low-resource languages.

\section{Data Description}
To begin with, we are given a bunch of files as part of data. We have
\begin{itemize}
    \item \textbf{se\_gold\_ur.tsv}: A tab-separated file containing Urdu lemmas mapped to BabelNet synset IDs. Some rows are empty (no projection possible). This serves as gold data for evaluation.
    \item \textbf{corebnout.txt}: A file with a filtered list BabelNet IDs, used for restricting the evaluation and for sense selection.
    \item \textbf{se\_gloss.tsv}: A tab-separated file containing BabelNet synset IDs and their English glosses (short definitions). Used to provide sense information for evaluation and for LLM Baseline's prompt.
    \item \textbf{se13\_sentences.tsv}: Contains the original English sentences. Each row typically corresponds to a unique sentence and its sentence ID.
    \item \textbf{se13\_tokens.tsv}: Lists the individual tokens (word/s) in each sentence, along with their sentence ID and token information including type, lemma, POS,	raw text	and instance ID. Essential for projections and alignments.
    \item \textbf{se13.key.tsv}: The gold-standard key for the English, specifying the correct sense(s) for each instance token in the English sentences.
    \item \textbf{xlwsd\_se13.xml}: An XML file packaging all the above information (sentences, tokenization, and sense annotations) for convenient input to WSD systems and evaluators.
\end{itemize}

\section{LLM Baseline}
The LLM Baseline was implemented using the model \textbf{google/gemma-3-4b-it} where we gave it a input of a English BabelNet synset gloss (definition) and ask it to generate a single-word Urdu word for each gloss using a large language model that best fits that definition. The procedure is as follows:

The model used is \textbf{google/gemma-3-4b-it}, accessed via the Hugging Face \texttt{transformers} library. Authentication is managed by supplying an \texttt{HF\_TOKEN} using the \texttt{huggingface\_hub} API. The model is loaded locally with automatic GPU support if available, or defaults to CPU otherwise. Tokenization and text generation both leverage the \texttt{transformers} library, ensuring efficient inference. Generation is performed on-device, so no calls to external APIs are made once the model is downloaded.

The code implemented here first reads all English glosses and their associated synset IDs from the file \texttt{se\_gloss.tsv}. For each gloss, it sends a prompt to the LLM requesting the best single Urdu word to match the definition. The prompt used here was 

\textit{"You are a bilingual lexicon expert.
Given a dictionary definition: \texttt{place holder for BabelNet gloss}, produce the single word in Urdu that best matches this definition. 
Provide only the one Urdu word without explanations!
DO NOT PROVIDE ANY OTHER OUPUT BUT THE URDU WORD!!
Example (Do not include OUTPUT in your response, here INPUT and OUTPUT are only present to help you distinguish INPUT and OUTPUT, they should not be present in the your response), 
(Only the urdu word must be present in your response)
Given INPUT prompt: You are a bilingual lexicon expert.
Given a dictionary definition: "burden", produce the single word in Urdu that best matches this definition. 
Provide only the one Urdu word without explanations!
DO NOT PROVIDE ANY OTHER OUPUT BUT THE URDU WORD!!
Expected OUTPUT response from you: \foreignlanguage{urdu}{بوج۔}
DO NOT REPEAT THE INPUT PRROMPT IN YOUR OUPUT ONLY GIVE THE URDU WORD!"}

This prompt design was iteratively refined to minimize off-target completions and suppress verbose that LLMs might otherwise default to. The concise style and explicit example helped steer the model towards a consistent template-based output format.
The model's Urdu response is collected and stored, mapping each BabelNet ID to its Urdu word from the LLM's response. 
The prompt is carefully engineered to output only a single Urdu word as the response, avoiding extraneous text, but the model outputs the input prompt along with the word hence the output is saved in a temperoroy file before post processing \texttt{urdu\_projections.tsv}.
The postprocessing script (\texttt{LLM\_Postprocessing.py}) organizes the model's output by cleaning the prompt from the output and storing only the urdu word as expected.


\subsection{Prompt Design and Justification}
\begin{itemize}
    \item The LLM is cast explicitly in the role of a ``bilingual lexicon expert.”
    \item The definition (English gloss) is quoted and passed in the prompt.
    \item The instructions demand ``the single word in Urdu that best matches this definition'' and ask explicitly for ``only the one Urdu word without explanations.”
    \item Several lines reinforce the instruction not to provide any additional output, context, or explanation—only the Urdu word.
    \item An explicit example is given in the prompt: for the definition ``burden,'' the expected model output is ``\RL{بوج}’’ (the Urdu word for burden).
    \item The instructions also warn the model not to repeat the prompt or template in its output.
\end{itemize}


\subsection{Number of Senses Generated per Synset}
\subsection{Examples, Errors, and Notable Cases}
(INCLUDE EXAMPLES SOME ERRORS SEEN IN THE FILE)

\section{Method}
\subsection{Translation}
\subsection{Alignment}
\subsection{Filtering}

\section{Analysis}
\subsection{Correct vs Incorrect Projections}
\subsection{Contextually Possible vs Impossible Equivalents}
\subsection{Sources of Error}
\subsection{Comparison with LLM Baseline}
\subsection{Automatic Evaluation}
\subsection{Impression}

\section{Conclusion}

\bibliographystyle{acl_natbib}
\bibliography{custom}

\section{Appendix}

\end{document}
