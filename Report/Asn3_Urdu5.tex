\documentclass[11pt]{article}
\usepackage{acl}
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{url}
\usepackage{booktabs}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage[english, bidi=basic]{babel}
\babelfont[urdu]{rm}{Amiri} % Urdu font setup

\setlength{\parskip}{0pt}

\author{
  \begin{tabular}{c c}
    \textbf{Chirooth Girigowda} & \textbf{Sahir Momin} \\
    \text{girigowd@ualberta.ca} & \text{smomin1@ualberta.ca} \\
    \text{University of Alberta} & \text{University of Alberta}
  \end{tabular}
}

\title{Assignment 3: Concepts \\ ExpandNet Implementation for English-to-Urdu Sense Projection}

\begin{document}
\maketitle

\section{Introduction}
We implement an English-to-Urdu sense projection pipeline using \textbf{ExpandNet}. Specifically, we translate English sentences into Urdu using the \textbf{facebook/nllb-200-distilled-600M} model. 
For alignment, we employ \textbf{DBAlign} with a bilingual English-Urdu dictionary, which combines lexical resources from \textbf{Kaikki.org} and the \textbf{GoldenDict} project. 
Alignments between English and Urdu tokens are obtained, and senses from English tokens are projected onto corresponding Urdu lemmas based on these alignments. 
This workflow enables ExtendNet to function for the English-Urdu pair, showcasing the adaptability of the sense projection approach to low-resource languages. 
Further dataset details are provided in the Appendix (\hyperref[sec:Data Description]{Data Description}).

\section{LLM Baseline}
Our baseline investigates whether a large language model (LLM) can accurately determine the primary sense of an English gloss and generate an appropriate Urdu translation.
The baseline uses \textbf{google/gemma-3-4b-it}\footnote{\url{https://huggingface.co/google/gemma-3-4b-it}}, prompting the model with an English BabelNet synset gloss (definition) and 
tasking it to produce a single Urdu word that best matches the definition.

The \textbf{google/gemma-3-4b-it} model is accessed via the Hugging Face \texttt{transformers} library, supporting efficient, on-device text generation. 
All synsets are read from \texttt{se\_gloss.tsv} (BabelNet ID and gloss). For each gloss, a prompt requests the best single Urdu word translation. 
Details of the prompt and rationale are included in the Appendix (\hyperref[sec:LLM Baseline Prompt]{LLM Baseline Prompt Design}).

Manual inspection revealed four major failure modes in the LLM outputs:
\begin{enumerate}
    \item The model often defaulted to generic verbs (e.g., ``\foreignlanguage{urdu}{کرنا}''(to do)), rather than specific content words.
    \item Output contamination by English formatting (e.g., ``you:coerce'').
    \item Failure to adhere to lemma constraints, producing multi-word phrases or agentive forms (e.g., ``\foreignlanguage{urdu}{جدوجہدکرنےوالا}''; `struggler') rather than root lemmas.
    \item Morphological fragmentation, most common with outputs like ``\foreignlanguage{urdu}{دری}'' (dari), a non-lexical suffix or sub-word unit, resulting in invalid Urdu lemmas.
\end{enumerate}

\section{Method}
We follow ExpandNet's official guidelines\footnote{\url{https://github.com/UAlberta-NLP/ExpandNet}} to project senses from English to Urdu. 
The released code supports only BabelNet IDs but was adapted to process WordNet IDs, for which we confirmed results were identical. 
The final filtering step of ExpandNet's code checks if an English token and its Urdu lemma are paired in the dictionary before projecting senses. 
However, due to the limited coverage of our Urdu dictionary, some source tokens were missing. 
To mitigate this, we relax this constraint by the following assumption: if an English word is absent from the dictionary, we assume a correct translation and project its sense to the corresponding Urdu lemma.

\subsection{Translation}
We use sentence translations from Assignment 2. We also experimented with Urdu LLMs, including \textbf{large-traversaal/Alif-1.0-8B-Instruct} \cite{shafique2025alif} and \textbf{google/gemma-3-4b-it}, 
but these models produced inferior results compared to \textbf{facebook/nllb-200-distilled-600M}\footnote{\url{https://huggingface.co/facebook/nllb-200-distilled-600M}} \cite{koishekenov-etal-2023-memory}. 
Typical errors in LLM outputs included incorrect Urdu usage and shifts in sentence meaning, as confirmed by our native speaker(L1) and co-author.

\subsection{Alignment}
To improve English-Urdu alignment, we constructed a comprehensive bilingual dictionary by merging two primary resources: 
(1) open-source dictionary files from GoldenDict\footnote{\url{http://goldendict.org/dictionaries.php}}; 
(2) a machine-readable Urdu dictionary from Kaikki.org\footnote{\url{https://kaikki.org/dictionary/Urdu/words/index.html}}, produced by Wiktextract \cite{ylonen2022wiktextract}. 
These were concatenated, cleaned (removing filler words), and used with \textbf{DBAlign}\footnote{\url{https://github.com/UAlberta-NLP/ExpandNet/blob/main/align_utils.py}} for alignment.

\subsection{Filtering}
The same merged dictionary is used to confirm valid English-to-Urdu token pairs before projecting senses. 
If an English token is not found in the dictionary, we assume a valid projection (as above).

\section{Analysis}
Evaluation showed that \textbf{98} senses annotated by ExpandNet were correct out of \textbf{715} evaluated. 
While many incorrect senses may be plausible in alternate contexts, they most often reflected contextual ambiguity rather than translation defects.

Manual analysis of a 10-sentence sample found: 39 projected senses, of which 27 were correct and 12 incorrect. 
Most errors were due to misalignment; e.g., English nouns (including entities) aligned with Urdu filler words, such as ``report'' aligned to ``\foreignlanguage{urdu}{ایک}'' ('one'), 
or ``American'' mapped to ``\foreignlanguage{urdu}{میں}'' ('in'). Multi-word concepts also presented problems (``death penalty'' sometimes reduced to ``\foreignlanguage{urdu}{موت}'' ('death')).

Alignment errors were the main source: over-general senses, inconsistent mapping, and filler words in dictionary entries led to projection failures, especially for low-resource languages like Urdu.

Our error analysis indicates noise in the merged dictionary: a high frequency of function words and stopwords resulted in alignments between English content words and Urdu fillers, producing many spurious projections.

\section{Results}
Quantitatively, ExpandNet outperforms the LLM baseline: ExpandNet achieved a sense-level F1 of 9.9, compared to 3.1 for the LLM baseline. The full table of results appears in the Appendix (\hyperref[table:results]{Table~1}).

\section{Conclusion and Discussion}
We implemented and analyzed two approaches for projecting English semantic senses onto Urdu: ExpandNet and a generative LLM baseline. 
While both face challenges typical of low-resource languages, \textbf{ExpandNet produced consistently better results} (F1 of 10.0 versus 3.1 for the LLM).

The core limitation for ExpandNet proved to be \textbf{alignment quality}: reliance on incomplete dictionaries means contentful English words may be mapped to Urdu fillers, limiting sense projection accuracy. 
The LLM, despite producing some fluent translations, failed to meet strict requirements for sense disambiguation, by returning single-word lemmas out of given context.

Although both systems performed modestly, ExpandNet achieved higher precision and recall, especially at synset level. 
Addressing these core limitations will require improved alignment methods, more comprehensive dictionaries, and higher-quality parallel data which is a common need across low-resource languages. 
Without better resources, the effectiveness of sense projection approaches will remain constrained.

\bibliographystyle{acl_natbib}
\bibliography{custom}

\section{Appendix}

\subsection{Data Description}
\label{sec:Data Description}
The dataset provided includes the following files:
\begin{itemize}\setlength\itemsep{0em}
    \item \textbf{se\_gold\_ur.tsv}: Urdu lemmas mapped to BabelNet synset IDs; empty rows indicate missing projections (gold standard).
    \item \textbf{corebnout.txt}: Filtered BabelNet IDs for restricted evaluation and sense selection.
    \item \textbf{se\_gloss.tsv}: BabelNet synset IDs with English glosses (definitions); drives LLM prompting and evaluation.
    \item \textbf{se13\_sentences.tsv}: Original English sentences, one row per sentence (with ID).
    \item \textbf{se13\_tokens.tsv}: Per-token information (sentence ID, token, lemma, POS, etc.); required for alignment and projections.
    \item \textbf{se13.key.tsv}: Gold standard English sense annotations for every instance token.
    \item \textbf{xlwsd\_se13.xml}: XML package of sentences, tokenization, and all sense annotations for input to WSD systems.
\end{itemize}

\subsection{LLM Baseline Prompt Design}
\label{sec:LLM Baseline Prompt}
The LLM baseline used the following prompt :

\begin{quote}
\textit{"You are a bilingual lexicon expert. 
Given a dictionary definition: \texttt{[placeholder for BabelNet gloss]}, produce the single word in Urdu that best matches this definition. 
Provide only the one Urdu word without explanations!
DO NOT PROVIDE ANY OTHER OUPUT BUT THE URDU WORD!!
Example (Do not include OUTPUT in your response, here INPUT and OUTPUT are only present to help you distinguish INPUT and OUTPUT, they should not be present in the your response), 
(Only the urdu word must be present in your response)
Given INPUT prompt: You are a bilingual lexicon expert.
Given a dictionary definition: "burden", produce the single word in Urdu that best matches this definition. 
Provide only the one Urdu word without explanations!
DO NOT PROVIDE ANY OTHER OUTPUT BUT THE URDU WORD!!
Expected OUTPUT response from you: \foreignlanguage{urdu}{بوج۔}
DO NOT REPEAT THE INPUT PROMPT IN YOUR OUTPUT, ONLY GIVE THE URDU WORD!"}
\end{quote}

The prompt design was iteratively refined to minimize off-target completions and suppress verbosity that LLMs might otherwise default to. The concise style and explicit example helped steer the model towards a consistent template-based output format.
The prompt was carefully engineered to output only a single Urdu word as the response, avoiding extraneous text, but the model's response always contained the input prompt along with the Urdu word. The input prompt was the only extraneous information that the LLM included in it's output.
Hence, the output from the LLM is saved in a temporary file and set to a postprocessing step where the model's response was cleaned by removing the input prompt from the output and storing only the Urdu word.

\begin{center}
\vspace*{-\topskip}
\vspace*{-\baselineskip}
\begingroup
\setlength{\abovecaptionskip}{5pt}
\setlength{\belowcaptionskip}{0pt}
\setlength{\floatsep}{0pt}
\setlength{\textfloatsep}{0pt}
\begin{minipage}{\textwidth}
\centering
\begin{tabular}{lccc}
\hline
\textbf{System}(Sense) & \textbf{P} & \textbf{R} & \textbf{F1} \\
\hline
LLM Baseline  & 4.2 & 2.5 & 3.1 \\
ExpandNet  & \textbf{13.7} & \textbf{7.7}  & \textbf{9.9} \\
\hline
\textbf{System}(Synset) & \textbf{P} & \textbf{R} & \textbf{F1} \\
\hline
LLM Baseline & 4.2 & 4.1 & 4.2 \\
ExpandNet & \textbf{15.8} & \textbf{12.4} & \textbf{13.9} \\
\hline
\end{tabular}
\hspace{2em}
\begin{tabular}{lc}
\hline
\textbf{System}(Synset) & \textbf{Core Coverage} \\
\hline
LLM Baseline & \textbf{6.1} \\
ExpandNet & 5.1 \\
\hline
\end{tabular}
\captionof{table}{Performance comparison of LLM Baseline and ExpandNet systems on Urdu sense projection. The top two sections report precision(P), recall(R), and F1 at the sense and synset levels respectively. The bottom section reports core synset coverage in \%.}
\label{table:results}
\end{minipage}
\endgroup
\end{center}

\end{document}
